{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN3_6OrKmLLw"
      },
      "source": [
        "# Querying a GitHub Codebase with Vertex AI RAG Engine\n",
        "\n",
        "This notebook demonstrates how to use Vertex AI's Retrieval-Augmented Generation (RAG) capabilities to index the code files from a public GitHub repository and then ask questions about that codebase using a generative model.\n",
        "\n",
        "It uses [Vertex AI RAG Engine](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/rag-overview), a component of the Vertex AI Platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHAP43Fy0YhR"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pRJeY2QzOI-"
      },
      "source": [
        "### Install Packages\n",
        "\n",
        "This cell installs the required Python libraries:\n",
        "*   [`google-cloud-aiplatform`](https://cloud.google.com/python/docs/reference/aiplatform/latest): The Vertex AI SDK for interacting with Vertex AI services like RAG and Gemini models.\n",
        "*   [`google-cloud-storage`](https://cloud.google.com/python/docs/reference/storage/latest): The SDK for interacting with Google Cloud Storage (GCS).\n",
        "*   [`gitpython`](https://gitpython.readthedocs.io/en/stable/): A library to interact with Git repositories (cloning).\n",
        "*   [`google-genai`](https://github.com/googleapis/python-genai): The Google Generative AI SDK (used here for simplified client interaction via `genai.Client`).\n",
        "\n",
        "It also restarts the Colab kernel, which is often necessary after installing new packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKcBsKEcKNII",
        "outputId": "26770c5c-6bcf-47e1-9e93-1e86c6d788cd"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage gitpython google-genai\n",
        "\n",
        "# Restart kernel after installs\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKpHAl0YzWQM"
      },
      "source": [
        "### Authentication\n",
        "\n",
        "This cell handles authentication, which is necessary to interact with Google Cloud services. If running in [Google Colab](https://colab.research.google.com/), it uses `google.colab.auth` to authenticate the user. If running in a different environment (like a local machine or a Vertex AI Workbench notebook), you might need to set up authentication differently (e.g., using `gcloud auth application-default login`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVRqm16zUQZF"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUq9DFpLzpwx"
      },
      "source": [
        "### Import Libraries\n",
        "\n",
        "Imports the necessary Python modules used throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXGfx19tKOCO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid\n",
        "\n",
        "import git\n",
        "from google import genai\n",
        "from google.cloud import storage\n",
        "from google.genai.types import GenerateContentConfig, Retrieval, Tool, VertexRagStore\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import vertexai\n",
        "from vertexai import rag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4ZFJoDP0hit"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvZzbGnizwOW"
      },
      "source": [
        "### Define Parameters\n",
        "\n",
        "Set the configuration variables required for the notebook. **You must replace placeholder values (like `[your-project-id]`, `[your-bucket-name]`) with your specific details.**\n",
        "\n",
        "*   `GITHUB_URL`: The URL of the public GitHub repository to index.\n",
        "*   `PROJECT_ID`: Your Google Cloud Project ID.\n",
        "*   `LOCATION`: The Google Cloud region where resources will be created (e.g., `us-central1`).\n",
        "*   `BUCKET_NAME`: The name of the GCS bucket used for staging code files. Ensure this bucket exists in your project.\n",
        "*   `GCS_FOLDER_PATH`: An optional prefix (folder path) within the bucket to organize the uploaded code files.\n",
        "*   `MAX_FILE_SIZE_MB`: A limit to skip uploading very large files (0 means no limit).\n",
        "*   `EMBEDDING_MODEL`: The [Vertex AI text embedding model](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings) used to create vector representations of the code chunks.\n",
        "*   `MODEL_ID`: The [Vertex AI Gemini model](https://cloud.google.com/vertex-ai/generative-ai/docs/models) used for answering questions.\n",
        "*   `RAG_CORPUS_DISPLAY_NAME`, `RAG_ENGINE_DISPLAY_NAME`: Unique display names for the RAG resources being created.\n",
        "*   `SUPPORTED_EXTENSIONS`: A list of file extensions and specific filenames to identify code, configuration, and documentation files for indexing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IByqXCKKXP-"
      },
      "outputs": [],
      "source": [
        "GITHUB_URL = \"https://github.com/google/adk-python\"  #@param {\"type\":\"string\", \"placeholder\": \"https://github.com/google/adk-python\"}\n",
        "PROJECT_ID = \"your-project-id\"  #@param {type:\"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "LOCATION = \"us-central1\"              #@param {type:\"string\"}\n",
        "BUCKET_NAME = \"your-bucket-name\"  #@param {type:\"string\", placeholder: \"[your-bucket-name]\", isTemplate: true}\n",
        "GCS_FOLDER_PATH = \"rag-code-data\" #@param {type:\"string\", placeholder: \"rag-code-data\", isTemplate: true} - The folder path (prefix) within the bucket where code files will be stored.\n",
        "MAX_FILE_SIZE_MB = 10 #@param {type:\"number\"} - Maximum individual file size in MB to upload. Set to 0 for no limit.\n",
        "EMBEDDING_MODEL = \"publishers/google/models/text-multilingual-embedding-002\"  # @param {type:\"string\", isTemplate: true}\n",
        "MODEL_ID = \"gemini-2.5-flash\"  # @param {type:\"string\", \"placeholder\": \"gemini-2.5-flash\", isTemplate: true}\n",
        "\n",
        "GCS_FOLDER_PATH = GCS_FOLDER_PATH.strip('/')\n",
        "BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n",
        "GCS_UPLOAD_URI = f\"{BUCKET_URI}/{GCS_FOLDER_PATH}\" if GCS_FOLDER_PATH else BUCKET_URI\n",
        "GCS_IMPORT_URI = f\"{GCS_UPLOAD_URI}/\"\n",
        "LOCAL_REPO_PATH = \"./cloned_repo\"\n",
        "\n",
        "# RAG Engine Configuration\n",
        "_UUID = uuid.uuid4()\n",
        "RAG_CORPUS_DISPLAY_NAME = f\"rag-corpus-code-{_UUID}\"\n",
        "RAG_ENGINE_DISPLAY_NAME = f\"rag-engine-code-{_UUID}\"\n",
        "\n",
        "# Supported file extensions for ingestion (adjust as needed)\n",
        "# Common code, config, and documentation file types\n",
        "SUPPORTED_EXTENSIONS = [\n",
        "    \".py\", \".java\", \".js\", \".ts\", \".go\", \".c\", \".cpp\", \".h\", \".hpp\",\n",
        "    \".cs\", \".rb\", \".php\", \".swift\", \".kt\", \".scala\",\n",
        "    \".md\", \".txt\", \".rst\", \".html\", \".css\", \".scss\",\n",
        "    \".yaml\", \".yml\", \".json\", \".xml\", \".proto\", \"Dockerfile\", \".sh\",\n",
        "    \".tf\", \".tfvars\", \".bicep\", \".gradle\", \"pom.xml\", \"requirements.txt\",\n",
        "    \"package.json\", \"go.mod\", \"go.sum\", \"Cargo.toml\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MdrHIhpz6uj"
      },
      "source": [
        "### Initialize API Clients\n",
        "\n",
        "Initializes the clients needed to interact with Google Cloud services using the specified `PROJECT_ID` and `LOCATION`.\n",
        "*   [`vertexai.init`](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai#vertexai_init): Initializes the Vertex AI SDK.\n",
        "*   [`genai.Client`](https://github.com/google/generative-ai-python/blob/v0.7.1/google/generativeai/client.py#L103): Creates a client for the Generative AI API (convenience wrapper).\n",
        "*   [`storage.Client`](https://cloud.google.com/python/docs/reference/storage/latest/google.cloud.storage.client.Client): Creates a client for Google Cloud Storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjOMa0RXTp-1"
      },
      "outputs": [],
      "source": [
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "storage_client = storage.Client(project=PROJECT_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjwokRJu00J2"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKsK8Tnq0BRx"
      },
      "source": [
        "### Clone GitHub Repository\n",
        "\n",
        "Clones the public Git repository specified by `GITHUB_URL` into a local directory (`./cloned_repo`). It uses the [`gitpython`](https://gitpython.readthedocs.io/en/stable/) library. Error handling is included in case the cloning fails (e.g., repository not found, network issues, directory already exists).\n",
        "\n",
        "*Note: The local path `./cloned_repo` is hardcoded in the `clone_from` command in this cell.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p7mBC9qWI5i",
        "outputId": "e5dcd85c-b9fe-49ed-9da5-90770a6a483b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  git.Repo.clone_from(GITHUB_URL, LOCAL_REPO_PATH)\n",
        "except git.GitCommandError as e:\n",
        "  print(f\"Error cloning repository: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zih1IBRg0Gtz"
      },
      "source": [
        "### Verify GCS Bucket Access\n",
        "\n",
        "Checks if the specified [Google Cloud Storage bucket](https://cloud.google.com/storage/docs/buckets) (`BUCKET_NAME`) exists and if the authenticated user or service account has permissions to access it. This helps catch configuration errors early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oazzsO8rWSY2",
        "outputId": "2218aba7-6535-4598-e29b-49598cff5dff"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    bucket = storage_client.get_bucket(BUCKET_NAME)\n",
        "    print(bucket.name)\n",
        "except Exception as e:\n",
        "    print(f\"Error accessing GCS bucket '{BUCKET_NAME}': {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIqN1El-0NHz"
      },
      "source": [
        "### Upload Code Files to GCS\n",
        "\n",
        "This cell walks through the locally cloned repository (`LOCAL_REPO_PATH`, implicitly `./cloned_repo` from the clone step) and uploads relevant files to the specified Google Cloud Storage bucket (`BUCKET_NAME`) and folder (`GCS_FOLDER_PATH`).\n",
        "\n",
        "Key actions:\n",
        "*   Skips the `.git` directory.\n",
        "*   Filters files based on `SUPPORTED_EXTENSIONS` (case-insensitive check).\n",
        "*   Optionally skips files larger than `MAX_FILE_SIZE_MB`.\n",
        "*   Preserves the relative directory structure within the specified GCS folder.\n",
        "*   Uploads files as [GCS objects (blobs)](https://cloud.google.com/storage/docs/objects).\n",
        "*   Prints progress and a final summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CezBxUyOasf0",
        "outputId": "a0aa3973-f61f-4011-9fa3-c503a53d485a"
      },
      "outputs": [],
      "source": [
        "uploaded_file_count = 0\n",
        "skipped_file_count = 0\n",
        "\n",
        "# Calculate max size in bytes once, if applicable\n",
        "max_bytes = 0\n",
        "if MAX_FILE_SIZE_MB > 0:\n",
        "    max_bytes = MAX_FILE_SIZE_MB * 1024 * 1024\n",
        "    print(f\"Applying max file size limit: {MAX_FILE_SIZE_MB} MB ({max_bytes} bytes)\")\n",
        "\n",
        "for root, dirs, files in os.walk(LOCAL_REPO_PATH):\n",
        "    # Skip '.git' directory explicitly to avoid uploading git metadata\n",
        "    if '.git' in dirs:\n",
        "        dirs.remove('.git')\n",
        "\n",
        "    for file in files:\n",
        "        file_lower = file.lower() # Use lowercase for case-insensitive checks\n",
        "        local_file_path = os.path.join(root, file)\n",
        "\n",
        "        # Check if the file has a supported extension (case-insensitive)\n",
        "        # or if the exact filename is in the list (e.g., \"Dockerfile\")\n",
        "        is_supported = any(file_lower.endswith(ext.lower()) for ext in SUPPORTED_EXTENSIONS) or \\\n",
        "                       file in SUPPORTED_EXTENSIONS # Check exact match for non-extension files\n",
        "\n",
        "        if is_supported:\n",
        "            try:\n",
        "                if max_bytes > 0: # Only check if a limit is set\n",
        "                    file_size_bytes = os.path.getsize(local_file_path)\n",
        "                    if file_size_bytes > max_bytes:\n",
        "                        print(f\"  Skipping large file ({(file_size_bytes / (1024*1024)):.2f} MB > {MAX_FILE_SIZE_MB} MB): {local_file_path}\")\n",
        "                        skipped_file_count += 1\n",
        "                        continue # Skip to the next file\n",
        "\n",
        "                # Create a relative path to maintain structure in GCS\n",
        "                relative_path = os.path.relpath(local_file_path, LOCAL_REPO_PATH)\n",
        "\n",
        "                # Construct the destination blob name within the specified GCS folder path\n",
        "                if GCS_FOLDER_PATH:\n",
        "                    gcs_blob_name = os.path.join(GCS_FOLDER_PATH, relative_path)\n",
        "                else:\n",
        "                    gcs_blob_name = relative_path\n",
        "                gcs_blob_name = gcs_blob_name.replace(\"\\\\\", \"/\")\n",
        "\n",
        "                # Get the blob object and upload the file\n",
        "                blob = bucket.blob(gcs_blob_name)\n",
        "                blob.upload_from_filename(local_file_path)\n",
        "                uploaded_file_count += 1\n",
        "\n",
        "                # Print progress periodically\n",
        "                if uploaded_file_count % 100 == 0:\n",
        "                    print(f\"  Uploaded {uploaded_file_count} files (skipped: {skipped_file_count})...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  Error uploading {local_file_path} to gs://{BUCKET_NAME}/{gcs_blob_name}: {e}\")\n",
        "\n",
        "# --- Final Report ---\n",
        "print(f\"\\nFinished uploading.\")\n",
        "print(f\"Total supported files uploaded: {uploaded_file_count}\")\n",
        "if skipped_file_count > 0:\n",
        "    print(f\"Total files skipped due to size limit: {skipped_file_count}\")\n",
        "\n",
        "if uploaded_file_count == 0:\n",
        "    print(f\"\\nWarning: No supported files were found (within size limits) in '{LOCAL_REPO_PATH}' or uploaded to '{GCS_UPLOAD_URI}'.\")\n",
        "    print(\"The RAG Engine will have no data from this source.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ZP3SNZ09Iz"
      },
      "source": [
        "## 4. RAG Corpus Creation\n",
        "\n",
        "Creates a [Vertex AI RAG Corpus](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/manage-your-rag-corpus). A RAG Corpus is a container for the documents (in this case, code files) that will be indexed for retrieval.\n",
        "\n",
        "*   It's configured with a display name and description.\n",
        "*   It specifies the `EMBEDDING_MODEL` to be used for generating vector embeddings of the file contents during the import process. The embeddings are stored in an underlying vector database managed by Vertex AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_LhE2BKGcsPk",
        "outputId": "6712b6e9-3e36-489b-f297-e15de3a00bed"
      },
      "outputs": [],
      "source": [
        "rag_corpus = rag.create_corpus(\n",
        "    display_name=RAG_CORPUS_DISPLAY_NAME,\n",
        "    description=f\"Codebase files from {GITHUB_URL}\",\n",
        "    backend_config=rag.RagVectorDbConfig(\n",
        "        rag_embedding_model_config=rag.RagEmbeddingModelConfig(\n",
        "            vertex_prediction_endpoint=rag.VertexPredictionEndpoint(\n",
        "                publisher_model=EMBEDDING_MODEL\n",
        "            )\n",
        "        )\n",
        "    )\n",
        ")\n",
        "rag_corpus.display_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTrkPyN11OA-"
      },
      "source": [
        "## 5. File Ingestion: Import Files into Corpus\n",
        "\n",
        "Starts the asynchronous process of importing files from the GCS location (`GCS_IMPORT_URI`) into the newly created `rag_corpus`.\n",
        "\n",
        "*   [`rag.import_files`](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-data-ingestion): Initiates the import job.\n",
        "*   **Chunking:** The `TransformationConfig` specifies how the files are processed before indexing. Here, `ChunkingConfig` defines that files are split into chunks of 500 tokens with an overlap of 100 tokens. Chunking is essential for RAG as it allows the model to retrieve smaller, more relevant pieces of information.\n",
        "\n",
        "This process can take some time depending on the number and size of files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YgYIonouHCr"
      },
      "outputs": [],
      "source": [
        "import_response = rag.import_files(\n",
        "    corpus_name=rag_corpus.name,\n",
        "    paths=[GCS_IMPORT_URI],\n",
        "    transformation_config=rag.TransformationConfig(\n",
        "        chunking_config=rag.ChunkingConfig(\n",
        "            chunk_size=1024,\n",
        "            chunk_overlap=256\n",
        "        )\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2VCR70q1gQR"
      },
      "source": [
        "## 6. RAG Tool Setup: Create Retrieval Tool\n",
        "\n",
        "Creates a `Tool` object that the Gemini model can use to perform retrieval from the RAG Corpus.\n",
        "\n",
        "*   [`Tool`](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.generative_models.Tool): A generic container for tools that generative models can use (e.g., function calling, retrieval).\n",
        "*   [`Retrieval`](https://googleapis.github.io/python-genai/genai.html#genai.types.Retrieval): Specifies a retrieval source.\n",
        "*   [`VertexRagStore`](https://googleapis.github.io/python-genai/genai.html#genai.types.VertexRagStore): Points the retrieval tool specifically to one or more Vertex AI RAG Corpora (`rag_corpora=[rag_corpus.name]`).\n",
        "  *   `similarity_top_k=10`: Instructs the tool to retrieve the top 10 most relevant chunks based on semantic similarity.\n",
        "  *   `vector_distance_threshold=0.5`: Sets a threshold for the vector distance; chunks with distances greater than this (less similar) might be filtered out. (Note: The interpretation might vary depending on the distance metric used by the embedding model).\n",
        "\n",
        "This tool configuration tells the Gemini model *how* to use the RAG Corpus when it needs external information to answer a query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gmkUvi-lFHX",
        "outputId": "ac5f17c1-f554-4608-99a4-22b97b845394"
      },
      "outputs": [],
      "source": [
        "rag_retrieval_tool = Tool(\n",
        "    retrieval=Retrieval(\n",
        "        vertex_rag_store=VertexRagStore(\n",
        "            rag_corpora=[rag_corpus.name],\n",
        "            similarity_top_k=10,\n",
        "            vector_distance_threshold=0.5,\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "rag_retrieval_tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK39YatR2JHZ"
      },
      "source": [
        "## Ask Questions about the Codebase\n",
        "\n",
        "Now, use the configured Gemini model (`MODEL_ID`) along with the `rag_retrieval_tool` to ask a question about the indexed codebase.\n",
        "\n",
        "*   The `GenerateContentConfig(tools=[rag_retrieval_tool])` tells the model it can use the RAG tool.\n",
        "*   When you provide a prompt (like \"What is the primary purpose...\"), the model first attempts to retrieve relevant chunks from the RAG Corpus using the tool.\n",
        "*   It then synthesizes an answer based on both its internal knowledge and the retrieved information from the codebase chunks.\n",
        "*   The response text is displayed as Markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "2UgKK9JDrn_Y",
        "outputId": "ee5c9408-5fc5-4a05-9a05-0d30da6ba9ef"
      },
      "outputs": [],
      "source": [
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=\"What is the primary purpose or main functionality of this codebase?\",\n",
        "    config=GenerateContentConfig(tools=[rag_retrieval_tool]),\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YImxWq-Y2P_b"
      },
      "source": [
        "## 8. Test in Vertex AI Studio\n",
        "\n",
        "This cell generates a direct clickable link to the [Vertex AI Studio](https://console.cloud.google.com/vertex-ai/studio) in the Google Cloud Console. The link is specifically constructed to open the Multimodal Studio page with the RAG Corpus created in this notebook already selected. This allows you to interactively test the RAG setup by asking questions directly in the UI.\n",
        "\n",
        "*   It URL-encodes the RAG Corpus resource name for use in the URL query parameters.\n",
        "*   It uses `IPython.display.HTML` to render a clickable link in the notebook output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "cPP-Q0kfpHw3",
        "outputId": "1c7e7320-6a4a-4ce7-ba35-29f322f50ace"
      },
      "outputs": [],
      "source": [
        "# URL encode the '/' characters in the resource name by replacing them with '%2F'\n",
        "encoded_rag_corpus_name = rag_corpus.name.replace(\"/\", \"%2F\")\n",
        "\n",
        "# Construct the full URL\n",
        "vertex_ai_studio_url = (\n",
        "    f\"https://console.cloud.google.com/vertex-ai/studio/multimodal\"\n",
        "    f\";ragCorpusName={encoded_rag_corpus_name}\"\n",
        "    f\"?project={PROJECT_ID}\"\n",
        ")\n",
        "\n",
        "# Create the HTML link\n",
        "link_text = f\"{rag_corpus.description}\"\n",
        "link_html = f'<a href=\"{vertex_ai_studio_url}\" target=\"_blank\">{link_text}</a>'\n",
        "\n",
        "# Display the clickable link in Colab output\n",
        "print(f\"Click to test the RAG Corpus in Vertex AI Studio:\")\n",
        "display(HTML(link_html))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2pRJeY2QzOI-",
        "IKsK8Tnq0BRx"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.12.4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
